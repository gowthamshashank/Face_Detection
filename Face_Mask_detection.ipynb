{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets Import the Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T17:10:49.992101Z",
     "start_time": "2021-01-30T17:10:41.108268Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "from keras.layers import Conv2D, Input, ZeroPadding2D\n",
    "from keras.layers import BatchNormalization, Activation, MaxPooling2D\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Model, load_model\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.metrics import Accuracy\n",
    "from keras import utils\n",
    "import imutils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T17:10:50.108505Z",
     "start_time": "2021-01-30T17:10:49.996237Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator,array_to_img,img_to_array,load_img\n",
    "import matplotlib as mt\n",
    "\n",
    "train_datagen = ImageDataGenerator(rotation_range=40,width_shift_range=.2,height_shift_range=.2,rescale=1./255,\n",
    "                                  shear_range=.2,zoom_range=.2,horizontal_flip=True,fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read The Train Directory of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T17:11:37.989460Z",
     "start_time": "2021-01-30T17:11:37.908697Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1178 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "train_data = train_datagen.flow_from_directory('/Users/gowthamshashank/downloads/Face_Detection/data-master/train',\n",
    "                                              target_size = (150,150),batch_size=batch_size,\n",
    "                                              class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read The Test Directory of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T17:11:51.521326Z",
     "start_time": "2021-01-30T17:11:51.500873Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 194 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data = test_datagen.flow_from_directory('/Users/gowthamshashank/downloads/Face_Detection/data-master/test/',\n",
    "                                            target_size=(150,150),batch_size=batch_size,\n",
    "                                            class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T17:11:52.914221Z",
     "start_time": "2021-01-30T17:11:52.727019Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 148, 148, 100)     2800      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 74, 74, 100)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 72, 72, 100)       90100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 100)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 129600)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 129600)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                6480050   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 6,573,052\n",
      "Trainable params: 6,573,052\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(100, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D(2,2),\n",
    "    \n",
    "    Conv2D(100, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dropout(0.5),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the compiler of cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T17:11:54.038649Z",
     "start_time": "2021-01-30T17:11:54.018153Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T17:12:35.443727Z",
     "start_time": "2021-01-30T17:11:55.217198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-1727a5f2eb04>:4: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 3s 673ms/step - loss: 1.7161 - acc: 0.4400 - val_loss: 0.6932 - val_acc: 0.5250\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 3s 633ms/step - loss: 0.6933 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.4250\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 3s 631ms/step - loss: 0.6932 - acc: 0.3800 - val_loss: 0.6932 - val_acc: 0.4000\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 3s 628ms/step - loss: 0.6932 - acc: 0.4000 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 3s 620ms/step - loss: 0.6932 - acc: 0.4400 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 3s 617ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.5250\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 3s 619ms/step - loss: 0.6932 - acc: 0.4400 - val_loss: 0.6932 - val_acc: 0.5500\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 3s 635ms/step - loss: 0.6932 - acc: 0.4800 - val_loss: 0.6932 - val_acc: 0.4750\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 3s 637ms/step - loss: 0.6932 - acc: 0.5200 - val_loss: 0.6932 - val_acc: 0.5500\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 3s 623ms/step - loss: 0.6932 - acc: 0.5625 - val_loss: 0.6932 - val_acc: 0.5500\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint('model2-{epoch:03d}.model',monitor='val_loss',\n",
    "                             verbose=0,save_best_only=True,mode='auto')\n",
    "\n",
    "history = model.fit_generator(train_data,steps_per_epoch=50//batch_size,epochs=10,\n",
    "                             validation_data=test_data,validation_steps=40//batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T17:12:58.099928Z",
     "start_time": "2021-01-30T17:12:57.884510Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save('mask_project.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Face Mask detection with opencv - Haar cascade  classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T17:12:59.045513Z",
     "start_time": "2021-01-30T17:12:59.040060Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from  keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T17:12:59.849786Z",
     "start_time": "2021-01-30T17:12:59.615305Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model('mask_project.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T17:13:00.116260Z",
     "start_time": "2021-01-30T17:13:00.109090Z"
    }
   },
   "outputs": [],
   "source": [
    "result={0:'without mask', 1:'mask'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T17:13:00.679591Z",
     "start_time": "2021-01-30T17:13:00.671413Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'without mask', 1: 'mask'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-30T17:29:54.270Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from  keras.models import load_model\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model('mask_project.h5')\n",
    "result={0:'without mask', 1:'mask'}\n",
    "\n",
    "GR_dict = {0:(0,0,255),1:(0,255,0)}\n",
    "\n",
    "rect_size = 4\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "haarcascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "while True:\n",
    "    (rval, im) = cap.read()\n",
    "    im=cv2.flip(im,1,1) \n",
    "\n",
    "    \n",
    "    rerect_size = cv2.resize(im, (im.shape[1] // rect_size, im.shape[0] // rect_size))\n",
    "    faces = haarcascade.detectMultiScale(rerect_size)\n",
    "    for f in faces:\n",
    "        (x, y, w, h) = [v * rect_size for v in f] \n",
    "        \n",
    "        face_img = im[y:y+h, x:x+w]\n",
    "        rerect_sized=cv2.resize(face_img,(150,150))\n",
    "        normalized=rerect_sized/255.0\n",
    "        reshaped=np.reshape(normalized,(1,150,150,30))\n",
    "        reshaped = np.vstack([reshaped])\n",
    "        result=model.predict(reshaped)\n",
    "\n",
    "        \n",
    "        label=np.argmax(result,axis=1)[0]\n",
    "      \n",
    "        cv2.rectangle(im,(x,y),(x+w,y+h),GR_dict[label],2)\n",
    "        cv2.rectangle(im,(x,y-40),(x+w,y),GR_dict[label],-1)\n",
    "        cv2.putText(im, result[label], (x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2)\n",
    "\n",
    "    cv2.imshow('LIVE',   im)\n",
    "    key = cv2.waitKey(10)\n",
    "    \n",
    "    if key == 27: \n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
